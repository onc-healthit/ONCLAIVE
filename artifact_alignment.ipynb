{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc613d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-anthropic in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (0.3.6)\n",
      "Collecting langchain-anthropic\n",
      "  Downloading langchain_anthropic-0.3.16-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting anthropic<1,>=0.52.0 (from langchain-anthropic)\n",
      "  Downloading anthropic-0.55.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain-anthropic)\n",
      "  Using cached langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from langchain-anthropic) (2.10.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.25.0 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from anthropic<1,>=0.52.0->langchain-anthropic) (4.12.2)\n",
      "Collecting langsmith>=0.3.45 (from langchain-core<1.0.0,>=0.3.66->langchain-anthropic)\n",
      "  Downloading langsmith-0.4.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.27.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.52.0->langchain-anthropic) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.52.0->langchain-anthropic) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.52.0->langchain-anthropic) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.52.0->langchain-anthropic) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.52.0->langchain-anthropic) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (3.10.14)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-anthropic)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jrockhill/miniconda3/envs/ONCL310/lib/python3.10/site-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-anthropic) (2.3.0)\n",
      "Downloading langchain_anthropic-0.3.16-py3-none-any.whl (29 kB)\n",
      "Downloading anthropic-0.55.0-py3-none-any.whl (289 kB)\n",
      "Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
      "Downloading langsmith-0.4.3-py3-none-any.whl (367 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-macosx_11_0_arm64.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m633.7/633.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: zstandard, langsmith, anthropic, langchain-core, langchain-anthropic\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.2.10\n",
      "    Uninstalling langsmith-0.2.10:\n",
      "      Successfully uninstalled langsmith-0.2.10\n",
      "  Attempting uninstall: anthropic\n",
      "    Found existing installation: anthropic 0.45.2\n",
      "    Uninstalling anthropic-0.45.2:\n",
      "      Successfully uninstalled anthropic-0.45.2\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.63\n",
      "    Uninstalling langchain-core-0.3.63:\n",
      "      Successfully uninstalled langchain-core-0.3.63\n",
      "  Attempting uninstall: langchain-anthropic\n",
      "    Found existing installation: langchain-anthropic 0.3.6\n",
      "    Uninstalling langchain-anthropic-0.3.6:\n",
      "      Successfully uninstalled langchain-anthropic-0.3.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.3.14 requires langsmith<0.3,>=0.1.17, but you have langsmith 0.4.3 which is incompatible.\n",
      "langchain-community 0.3.14 requires langsmith<0.3,>=0.1.125, but you have langsmith 0.4.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed anthropic-0.55.0 langchain-anthropic-0.3.16 langchain-core-0.3.66 langsmith-0.4.3 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%export` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4f1df25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "from ragas import evaluate\n",
    "from pipeline.llm_utils import LLMApiClient\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "from ragas import EvaluationDataset\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from copy import deepcopy\n",
    "from langchain_anthropic import ChatAnthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "451adbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_ds = Dataset.from_csv(\"Plan Net Requirements(1.1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdbd0383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Section #': '5.1.2',\n",
       " 'Link': 'http://hl7.org/fhir/us/davinci-pdex-plan-net/STU1.1/implementation.html#privacy-considerations-1',\n",
       " 'Section Title': 'Privacy Considerations',\n",
       " 'Requirement': 'A conformant Plan-Net service SHALL NOT require a directory mobile application to send consumer identifying information in order to query content.',\n",
       " 'Conformance': 'SHALL NOT',\n",
       " 'Target': 'Server',\n",
       " 'Requirement Id (See 1.1.0 Tests tab)': 'S-NoPII',\n",
       " 'Tested?': 'No',\n",
       " 'Tested Response Details': 'Untestable',\n",
       " 'Testable? (see Testability and Test Approach Tab)': 'No',\n",
       " 'Notes / Questions': 'Can this be approximated by requiring that authentication details not be sent?',\n",
       " 'Target Draft Scope': 'No',\n",
       " 'Status': 'NA',\n",
       " 'JIRA links': ''}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6146fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../internal_onclaive/onclaive/reqs_extraction/experiment_output/rag-lite-plannet-reqs-processed_v0.json\") as f:\n",
    "    ragreqs = json.load(f)\n",
    "# with open(\"../internal_onclaive/onclaive/reqs_extraction/experiment_output/rag-lite-plannet-reqs.json\") as f:\n",
    "#     ragreqs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55f7f441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['file_name', 'chunk_index', 'total_chunks', 'chunk', 'response', 'llm_response', 'selected_examples', 'processed_requirements'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragreqs[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "070f0e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 162\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for entry in ragreqs:\n",
    "    if 'processed_requirements' in entry:\n",
    "        i += 1\n",
    "print(i, len(ragreqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb8098f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "            model_name=\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "088bbdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_strings = []\n",
    "for entry in ragreqs:\n",
    "    if 'processed_requirements' in entry:\n",
    "        for req in entry['processed_requirements']:\n",
    "            rag_strings.append({'requirement_text': req['Requirement*'], 'requirement_object': req, 'chunk': entry['chunk']})\n",
    "\n",
    "rag_ds = Dataset.from_list(rag_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = ef.embed_with_retries(rag_strings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae5644f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_vectors = ef.embed_with_retries(human_ds['Requirement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c4826b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = pairwise_distances(vectors, Y=human_vectors, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c510d103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(575, 40)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcd955b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.691572  , 0.6874276 , 0.72738445, ..., 0.7919129 , 0.7919129 ,\n",
       "        0.70331466],\n",
       "       [0.724698  , 0.75139505, 0.5967315 , ..., 0.69035614, 0.69035614,\n",
       "        0.64132285],\n",
       "       [0.70380485, 0.75014585, 0.63428867, ..., 0.6823095 , 0.6823095 ,\n",
       "        0.62140566],\n",
       "       ...,\n",
       "       [0.8861651 , 0.90680355, 0.79491925, ..., 0.93528754, 0.93528754,\n",
       "        0.8136785 ],\n",
       "       [0.7201339 , 0.72039175, 0.6750707 , ..., 0.64340734, 0.64340734,\n",
       "        0.80129313],\n",
       "       [0.8521931 , 0.90468967, 0.913733  , ..., 0.8979242 , 0.8979242 ,\n",
       "        0.81516   ]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa1f4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a03121e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([569, 569,  88,  88, 404, 569, 481,  88, 569, 574, 461, 574, 211,\n",
       "        57, 115, 115, 542,  88,  86,  86, 409, 409, 574, 421, 189, 574,\n",
       "       530, 463, 556, 574, 549, 387, 387, 387, 387, 387, 112, 111, 111,\n",
       "       305])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(mat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dfbe60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(rag_strings.keys())[x] for x in np.argmax(mat, axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5d9fba47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Actor*': 'Server',\n",
       " 'Conformance*': 'SHALL',\n",
       " 'Grouping': 'Terminology',\n",
       " 'Notes': None,\n",
       " 'Planning To Test Details': None,\n",
       " 'Planning To Test?': 'Yes',\n",
       " 'Questions': None,\n",
       " 'Requirement*': \"Server SHALL support the CodeSystem 'DeliveryMethodCS' with URL 'http://hl7.org/fhir/us/davinci-pdex-plan-net/CodeSystem/DeliveryMethodCS'\",\n",
       " 'Simulation Approach': 'SIMULATED: Inferno will include this CodeSystem in its terminology validation.',\n",
       " 'Test Plan': 'Verify that the server supports the DeliveryMethodCS CodeSystem by validating a resource that uses a code from this CodeSystem.',\n",
       " 'Test name': None,\n",
       " 'Verifiable?': 'Yes',\n",
       " 'client testing simulation implementation group': None}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_ds[0]['requirement_object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dcb27d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Section #': '5.1.2',\n",
       " 'Link': 'http://hl7.org/fhir/us/davinci-pdex-plan-net/STU1.1/implementation.html#privacy-considerations-1',\n",
       " 'Section Title': 'Privacy Considerations',\n",
       " 'Requirement': 'A conformant Plan-Net service SHALL NOT require a directory mobile application to send consumer identifying information in order to query content.',\n",
       " 'Conformance': 'SHALL NOT',\n",
       " 'Target': 'Server',\n",
       " 'Requirement Id (See 1.1.0 Tests tab)': 'S-NoPII',\n",
       " 'Tested?': 'No',\n",
       " 'Tested Response Details': 'Untestable',\n",
       " 'Testable? (see Testability and Test Approach Tab)': 'No',\n",
       " 'Notes / Questions': 'Can this be approximated by requiring that authentication details not be sent?',\n",
       " 'Target Draft Scope': 'No',\n",
       " 'Status': None,\n",
       " 'JIRA links': None}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a90d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj = list(zip(human_ds.to_list(), [dict(rag_ds[int(x)]) for x in np.argmax(mat, axis=0)]))\n",
    "\n",
    "# with open(\"temp_pairs.json\", \"w+\") as f:\n",
    "#     json.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2afc6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp_pairs.json') as f:\n",
    "    pairs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db901da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs = zip(human_ds, [rag_ds[int(x)] for x in np.argmax(mat, axis=0)])\n",
    "dataset = []\n",
    "\n",
    "PROMPT_2_PATH = \"prompts/requirement_extraction_rag.txt\"\n",
    "\n",
    "with open(PROMPT_2_PATH, 'r') as f:\n",
    "    PROMPT_2 = f.read()\n",
    "\n",
    "for human,rag in pairs:\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\":PROMPT_2,\n",
    "            \"retrieved_contexts\":[str(rag['chunk'])],\n",
    "            \"response\":str(rag['requirement_object']),\n",
    "            \"reference\":str(human)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc64efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatAnthropic(model_name=\"claude-3-5-sonnet-20241022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d19d170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f31bcdd0ab67434ca02730de2e3c1a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[8]: TimeoutError()\n",
      "Exception raised in Job[28]: TimeoutError()\n",
      "Exception raised in Job[49]: TimeoutError()\n",
      "Exception raised in Job[66]: TimeoutError()\n",
      "Exception raised in Job[73]: TimeoutError()\n",
      "Exception raised in Job[75]: TimeoutError()\n",
      "Exception raised in Job[79]: TimeoutError()\n",
      "Exception raised in Job[108]: TimeoutError()\n",
      "Exception raised in Job[111]: TimeoutError()\n"
     ]
    }
   ],
   "source": [
    "evald = EvaluationDataset.from_list(dataset)\n",
    "\n",
    "result = evaluate(dataset=evald, metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()], llm=LangchainLLMWrapper(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d88e309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12ed0dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = zip(*list(df.iloc[:,2:4].iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec55ca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Actor*': 'Server', 'Conformance*': 'SHALL', 'Grouping': 'Search', 'Notes': None, 'Planning To Test Details': None, 'Planning To Test?': 'Yes', 'Questions': None, 'Requirement*': \"The 'address' search parameter for Location resources SHALL support multiple 'AND' instances of the parameter.\", 'Simulation Approach': \"SIMULATED: Inferno will implement support for multiple 'AND' instances of the parameter in its Location search endpoint.\", 'Test Plan': \"Execute a search against the server's Location endpoint using multiple instances of the 'address' parameter, verifying that the server returns results matching all of the provided values.\", 'Test name': None, 'Verifiable?': 'Yes', 'client testing simulation implementation group': 'Search'}\n",
      "{'Section #': '5.1.2', 'Link': 'http://hl7.org/fhir/us/davinci-pdex-plan-net/STU1.1/implementation.html#privacy-considerations-1', 'Section Title': 'Privacy Considerations', 'Requirement': 'A conformant Plan-Net service SHALL NOT require a directory mobile application to send consumer identifying information in order to query content.', 'Conformance': 'SHALL NOT', 'Target': 'Server', 'Requirement Id (See 1.1.0 Tests tab)': 'S-NoPII', 'Tested?': 'No', 'Tested Response Details': 'Untestable', 'Testable? (see Testability and Test Approach Tab)': 'No', 'Notes / Questions': 'Can this be approximated by requiring that authentication details not be sent?', 'Target Draft Scope': 'No', 'Status': None, 'JIRA links': None}\n"
     ]
    }
   ],
   "source": [
    "print(b[0].response)\n",
    "print(b[0].reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "36955da8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Anthropic' object has no attribute 'generate_prompt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mLangchainLLMWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclaude\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest input\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ONCL310/lib/python3.10/site-packages/ragas/llms/base.py:219\u001b[0m, in \u001b[0;36mLangchainLLMWrapper.generate_text\u001b[0;34m(self, prompt, n, temperature, stop, callbacks)\u001b[0m\n\u001b[1;32m    212\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlangchain_llm\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[1;32m    213\u001b[0m         prompts\u001b[38;5;241m=\u001b[39m[prompt],\n\u001b[1;32m    214\u001b[0m         n\u001b[38;5;241m=\u001b[39mn,\n\u001b[1;32m    215\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    216\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 219\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlangchain_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m(\n\u001b[1;32m    220\u001b[0m         prompts\u001b[38;5;241m=\u001b[39m[prompt] \u001b[38;5;241m*\u001b[39m n,\n\u001b[1;32m    221\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    222\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    223\u001b[0m     )\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# make LLMResult.generation appear as if it was n_completions\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# note that LLMResult.runs is still a list that represents each run\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     generations \u001b[38;5;241m=\u001b[39m [[g[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mgenerations]]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Anthropic' object has no attribute 'generate_prompt'"
     ]
    }
   ],
   "source": [
    "LangchainLLMWrapper(clients.clients['claude']).generate_text(\"test input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f979ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Requirement*': \"Server SHALL support the CodeSystem 'DeliveryMethodCS' with URL 'http://hl7.org/fhir/us/davinci-pdex-plan-net/CodeSystem/DeliveryMethodCS'\",\n",
       " 'Conformance*': 'SHALL',\n",
       " 'Actor*': 'Server',\n",
       " 'Verifiable?': 'Yes',\n",
       " 'Planning To Test?': 'Yes',\n",
       " 'Grouping': 'Terminology',\n",
       " 'Test Plan': 'Verify that the server supports the DeliveryMethodCS CodeSystem by validating a resource that uses a code from this CodeSystem.',\n",
       " 'Simulation Approach': 'SIMULATED: Inferno will include this CodeSystem in its terminology validation.'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rag_strings.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33915a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"20250627_Claude_RAGAS_Requirement_generation_eval_v0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ad2487",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ONCL310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
